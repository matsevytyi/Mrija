{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLzUXGbOU3Dv",
        "outputId": "ce832c72-272a-40fd-e629-dc225a47404c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ],
      "source": [
        "#!pip install transformers\n",
        "#!pip install torch\n",
        "!pip install faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "NedK-x39QmK9"
      },
      "outputs": [],
      "source": [
        "# necessary imports\n",
        "\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFUJuD5YRjLK",
        "outputId": "9d365d9a-6080-4062-f467-36357bf5f304"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4.76 5.04 4.48 3.64 4.48 5.32]\n"
          ]
        }
      ],
      "source": [
        "# loading test data\n",
        "\n",
        "user_data = [\n",
        "    [\"13.12.2023 17:14:56\", 4.76, 5.04, 4.48, 3.64, 4.48, 5.32],\n",
        "    [\"13.12.2023 17:21:03\", 3.64, 3.92, 3.92, 3.64, 3.64, 3.92],\n",
        "    [\"13.12.2023 17:47:13\", 5.88, 6.44, 6.65, 7.00, 5.60, 5.32],\n",
        "    [\"13.12.2023 18:03:34\", 2.52, 1.40, 5.88, 2.24, 4.20, 1.96],\n",
        "    [\"13.12.2023 18:05:36\", 5.88, 7.00, 5.04, 4.76, 7.00, 4.76],\n",
        "    [\"13.12.2023 18:09:50\", 3.36, 4.76, 7.00, 3.64, 3.36, 4.48],\n",
        "    [\"13.12.2023 18:42:14\", 6.44, 5.88, 3.64, 3.64, 4.76, 5.32],\n",
        "    [\"13.12.2023 19:18:19\", 4.76, 5.04, 2.24, 4.48, 3.36, 4.20],\n",
        "    [\"13.12.2023 21:09:46\", 5.04, 6.16, 6.44, 5.88, 5.88, 5.60],\n",
        "    [\"16.12.2023 11:36:37\", 4.20, 3.92, 3.92, 4.48, 4.48, 5.04],\n",
        "    [\"16.12.2023 13:02:24\", 5.88, 7.00, 7.00, 7.00, 7.00, 7.00],\n",
        "    [\"16.12.2023 13:07:36\", 4.20, 4.76, 4.48, 4.20, 4.20, 4.76],\n",
        "    [\"16.12.2023 16:12:31\", 5.04, 7.00, 3.92, 5.60, 7.00, 6.72],\n",
        "    [\"16.12.2023 16:16:46\", 4.76, 6.44, 4.76, 4.76, 7.00, 5.32],\n",
        "    [\"16.12.2023 16:17:51\", 6.44, 6.16, 4.48, 5.04, 5.04, 5.88],\n",
        "    [\"16.12.2023 16:33:55\", 4.20, 6.72, 7.00, 3.36, 4.76, 4.76],\n",
        "    [\"16.12.2023 18:38:24\", 3.92, 4.20, 4.48, 5.88, 5.88, 4.20],\n",
        "    [\"16.12.2023 18:58:30\", 4.20, 5.32, 5.88, 5.32, 4.48, 5.60],\n",
        "    [\"17.12.2023 09:45:31\", 5.32, 6.44, 5.32, 3.64, 2.80, 6.72],\n",
        "    [\"17.12.2023 09:48:34\", 5.32, 4.20, 1.96, 1.96, 3.08, 3.92],\n",
        "    [\"17.12.2023 22:22:43\", 4.20, 5.32, 4.48, 5.04, 5.04, 5.88],\n",
        "    [\"17.12.2023 23:17:10\", 5.04, 6.44, 5.32, 6.44, 5.88, 5.60],\n",
        "    [\"18.12.2023 14:25:16\", 4.48, 4.76, 3.64, 4.48, 4.76, 5.04],\n",
        "    [\"23.12.2023 07:38:09\", 3.64, 5.88, 2.52, 3.08, 4.76, 5.60],\n",
        "]\n",
        "\n",
        "columns = [\"Timestamp\", \"Realistic\", \"Investigative\", \"Artistic\", \"Social\", \"Enterprising\", \"Conventional\"]\n",
        "\n",
        "user_data = pd.DataFrame(user_data, columns=columns)\n",
        "\n",
        "#print(user_data)\n",
        "\n",
        "print(np.array(user_data.iloc[0, 1:]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "BWAlF_2OsFbz"
      },
      "outputs": [],
      "source": [
        "def preprocess_to_faiss(df):\n",
        "\n",
        "    # normalize\n",
        "    df = df / np.linalg.norm(df, axis=1, keepdims=True)\n",
        "\n",
        "    index = faiss.IndexFlatIP(df.shape[1]) # Inner Product for cosine similarity)\n",
        "    index.add(df)\n",
        "\n",
        "    return index\n",
        "\n",
        "\n",
        "def find_similar_with_faiss(user_riasec, index, top_k=100): # quickly sort and retrieve top 100 results\n",
        "\n",
        "    # normalize\n",
        "    user_riasec = user_riasec / np.linalg.norm(user_riasec)\n",
        "\n",
        "    # top_k most similar professions\n",
        "    distances, indices = index.search(user_riasec.reshape(1, -1), top_k)\n",
        "\n",
        "    return distances.flatten(), indices.flatten()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMOjzQf2u11W",
        "outputId": "c5ae53a3-002d-4b00-bb75-1362d989f49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of                                     profession  R_score  I_score  A_score  \\\n",
            "0                             Chief Executives     1.33     2.00     2.67   \n",
            "1                Chief Sustainability Officers     1.00     4.33     2.67   \n",
            "2              General and Operations Managers     1.33     1.33     1.00   \n",
            "3                                  Legislators     1.00     3.67     3.67   \n",
            "4          Advertising and Promotions Managers     1.67     2.00     5.33   \n",
            "..                                         ...      ...      ...      ...   \n",
            "969    Pump Operators, Except Wellhead Pumpers     7.00     4.00     1.00   \n",
            "970                           Wellhead Pumpers     7.00     3.67     1.00   \n",
            "971  Refuse and Recyclable Material Collectors     7.00     1.33     1.00   \n",
            "972                 Mine Shuttle Car Operators     7.00     1.33     1.00   \n",
            "973          Tank Car, Truck, and Ship Loaders     7.00     3.00     1.00   \n",
            "\n",
            "     S_score  E_score  C_score  HP_1  HP_2  HP_3  \n",
            "0       3.67     7.00     5.33     5     6     0  \n",
            "1       2.33     7.00     4.33     5     6     2  \n",
            "2       3.33     7.00     3.67     5     6     4  \n",
            "3       4.67     7.00     3.00     5     4     0  \n",
            "4       2.33     7.00     4.67     5     3     6  \n",
            "..       ...      ...      ...   ...   ...   ...  \n",
            "969     1.33     2.00     4.67     1     6     2  \n",
            "970     1.00     1.33     5.00     1     6     2  \n",
            "971     1.00     2.33     3.67     1     6     0  \n",
            "972     1.00     1.67     2.33     1     0     0  \n",
            "973     1.33     2.00     5.00     1     6     0  \n",
            "\n",
            "[974 rows x 10 columns]>\n",
            "[['Forest and Conservation Technicians' 0.9705954194068909]\n",
            " ['Web Developers' 0.9701500535011292]\n",
            " ['Ophthalmic Medical Technologists' 0.9675334692001343]\n",
            " ['Database Architects' 0.9668979644775391]\n",
            " ['Instructional Designers and Technologists' 0.9668335318565369]\n",
            " ['Computer Network Architects' 0.9610024094581604]\n",
            " ['Curators' 0.9572728872299194]\n",
            " ['Intelligence Analysts' 0.9565085172653198]\n",
            " ['Environmental Engineers' 0.9545261859893799]\n",
            " ['Operations Research Analysts' 0.9535020589828491]\n",
            " ['Database Administrators' 0.9530766010284424]\n",
            " ['Atmospheric and Space Scientists' 0.9526832103729248]\n",
            " ['Security Management Specialists' 0.9523783922195435]\n",
            " ['Magnetic Resonance Imaging Technologists' 0.9523530006408691]\n",
            " ['Computer User Support Specialists' 0.9503675699234009]\n",
            " ['Fire-Prevention and Protection Engineers' 0.9501739144325256]\n",
            " ['Architectural Drafters' 0.9500235319137573]\n",
            " ['Industrial Safety and Health Engineers' 0.9497923851013184]\n",
            " ['Network and Computer Systems Administrators' 0.9487754106521606]\n",
            " ['Electronic Drafters' 0.9487001299858093]\n",
            " ['Human Factors Engineers and Ergonomists' 0.9474164843559265]\n",
            " ['Fire Investigators' 0.9464510679244995]\n",
            " ['Electronics Engineers, Except Computer' 0.9464502334594727]\n",
            " ['Urban and Regional Planners' 0.9453939199447632]\n",
            " ['City and Regional Planning Aides' 0.944903552532196]\n",
            " ['Transportation Planners' 0.9445808529853821]\n",
            " ['Electrical Drafters' 0.9443828463554382]\n",
            " ['Archeologists' 0.9439074397087097]\n",
            " ['Airfield Operations Specialists' 0.9415643215179443]\n",
            " ['Validation Engineers' 0.9414999485015869]\n",
            " ['Computer Systems Analysts' 0.9413628578186035]\n",
            " ['Web Administrators' 0.9410346746444702]\n",
            " ['Water/Wastewater Engineers' 0.9401324391365051]\n",
            " ['Information Security Analysts' 0.9400815367698669]\n",
            " ['Cytogenetic Technologists' 0.9400414228439331]\n",
            " ['Coroners' 0.9399676322937012]\n",
            " ['Cartographers and Photogrammetrists' 0.9398196339607239]\n",
            " ['Police Detectives' 0.9383469223976135]\n",
            " ['Museum Technicians and Conservators' 0.9376629590988159]\n",
            " ['Cooks, Private Household' 0.9375416040420532]\n",
            " ['Medical Transcriptionists' 0.9370895624160767]\n",
            " ['Industrial Engineers' 0.9365318417549133]\n",
            " ['Wind Energy Engineers' 0.9362500905990601]\n",
            " ['Fire Inspectors' 0.9361057877540588]\n",
            " ['Civil Drafters' 0.9357410669326782]\n",
            " ['Civil Engineering Technicians' 0.9357149600982666]\n",
            " ['Occupational Health and Safety Technicians' 0.9356410503387451]\n",
            " ['Industrial Engineering Technicians' 0.9353273510932922]\n",
            " ['Anthropologists' 0.9350615739822388]\n",
            " ['Environmental Compliance Inspectors' 0.9347128868103027]\n",
            " ['Surveyors' 0.9340355396270752]\n",
            " ['Occupational Health and Safety Specialists' 0.9340002536773682]\n",
            " ['Landscape Architects' 0.9339612126350403]\n",
            " ['Soil and Water Conservationists' 0.9337988495826721]\n",
            " ['Embalmers' 0.9337552785873413]\n",
            " ['Compliance Managers' 0.933725118637085]\n",
            " ['Sustainability Specialists' 0.9336138367652893]\n",
            " ['Nanosystems Engineers' 0.9333814382553101]\n",
            " ['Financial Quantitative Analysts' 0.9331620931625366]\n",
            " ['Exercise Physiologists' 0.9327067732810974]\n",
            " ['Baristas' 0.9324420690536499]\n",
            " ['Logistics Engineers' 0.932441234588623]\n",
            " ['Computer Programmers' 0.9321427941322327]\n",
            " ['Materials Scientists' 0.9319208264350891]\n",
            " ['Electromechanical Engineering Technologists' 0.9316672086715698]\n",
            " ['Audio-Visual and Multimedia Collections Specialists'\n",
            "  0.9315477013587952]\n",
            " ['Food Scientists and Technologists' 0.9309688210487366]\n",
            " ['Desktop Publishers' 0.9309400320053101]\n",
            " ['Economists' 0.9309101700782776]\n",
            " ['Archivists' 0.9308516383171082]\n",
            " ['Ophthalmic Medical Technicians' 0.9308287501335144]\n",
            " ['Informatics Nurse Specialists' 0.9306274056434631]\n",
            " ['Civil Engineers' 0.9304567575454712]\n",
            " ['Software Developers, Systems Software' 0.9304124116897583]\n",
            " ['Industrial Engineering Technologists' 0.930037260055542]\n",
            " ['Police Identification and Records Officers' 0.929980456829071]\n",
            " ['Climate Change Analysts' 0.929915189743042]\n",
            " ['Librarians' 0.9298051595687866]\n",
            " ['Computer and Information Systems Managers' 0.9294918775558472]\n",
            " ['Materials Engineers' 0.9293549656867981]\n",
            " ['Barbers' 0.9292499423027039]\n",
            " ['Agricultural Engineers' 0.9289188385009766]\n",
            " ['Marine Engineers' 0.9289183020591736]\n",
            " ['Anesthesiologists' 0.9285232424736023]\n",
            " ['Software Developers, Applications' 0.928496778011322]\n",
            " ['Dental Laboratory Technicians' 0.9282057285308838]\n",
            " ['Water Resource Specialists' 0.9281593561172485]\n",
            " ['Biomedical Engineers' 0.9281330704689026]\n",
            " ['Fuel Cell Engineers' 0.9280791282653809]\n",
            " ['Medical and Clinical Laboratory Technicians' 0.9280077219009399]\n",
            " ['Surgeons' 0.9277657270431519]\n",
            " ['Neurodiagnostic Technologists' 0.9277509450912476]\n",
            " ['Financial Analysts' 0.9263148903846741]\n",
            " ['Architects, Except Landscape and Naval' 0.9262998104095459]\n",
            " ['Brownfield Redevelopment Specialists and Site Managers'\n",
            "  0.9262608885765076]\n",
            " ['Data Warehousing Specialists' 0.9261505603790283]\n",
            " ['Mining and Geological Engineers, Including Mining Safety Engineers'\n",
            "  0.9261472225189209]\n",
            " ['Dental Assistants' 0.9260945320129395]\n",
            " ['Mechanical Drafters' 0.925241231918335]\n",
            " ['Search Marketing Strategists' 0.924970805644989]]\n"
          ]
        }
      ],
      "source": [
        "# loading riasec data\n",
        "\n",
        "jd = pd.read_excel(\"Processed_Interests.xlsx\")\n",
        "\n",
        "print(jd.head)\n",
        "\n",
        "riasec_columns = [\"R_score\", \"I_score\", \"A_score\", \"S_score\", \"E_score\", \"C_score\"]\n",
        "processed_jd = jd[riasec_columns]\n",
        "\n",
        "# Preprocess tto the faiss\n",
        "jd_faiss = preprocess_to_faiss(processed_jd)\n",
        "\n",
        "# get similar professions\n",
        "distances, indices = find_similar_with_faiss(np.array(user_data.iloc[0, 1:]), jd_faiss, top_k=100)\n",
        "answer = np.column_stack((jd.iloc[indices, 0], distances))\n",
        "\n",
        "print(answer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "ReUs0w5-4nxv"
      },
      "outputs": [],
      "source": [
        "# prepare LLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "RvWbQi8LSKmD",
        "outputId": "5200c008-1cb5-4ced-9370-779417b91dee"
      },
      "outputs": [],
      "source": [
        "# processing text-based answers embeddings\n",
        "\n",
        "def extract_embeddings(texts, max_length=128):\n",
        "\n",
        "    encoded_inputs = tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_inputs)\n",
        "\n",
        "    embeddings = output.last_hidden_state[:, 0, :]  # Shape: (batch_size, hidden_size)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj2NjQfa4eHs",
        "outputId": "ce4e4070-01cc-433a-f6b8-cad0861b64bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['math', 'informatics']\n",
            "torch.Size([2, 768])\n"
          ]
        }
      ],
      "source": [
        "# extracting insights from the user answer\n",
        "\n",
        "base_words = [\"math\", \"chemistry\", \"physical education\", \"history\", \"literature\", \"biology\", \"physics\"] # no need to specify all of them\n",
        "school_subject = \"school subject\"\n",
        "\n",
        "base_embeddings = extract_embeddings(base_words)\n",
        "school_subject_embedding = extract_embeddings([school_subject])\n",
        "\n",
        "def clean_text(user_input):\n",
        "\n",
        "    # tokenize the user input and make embeddings\n",
        "    user_input_tokens = tokenizer.tokenize(user_input.lower())\n",
        "\n",
        "    user_input_embeddings = extract_embeddings(user_input_tokens)\n",
        "\n",
        "    relevant_subjects = []\n",
        "\n",
        "    # compare each user input token to the base words and school subject\n",
        "    for token, token_embedding in zip(user_input_tokens, user_input_embeddings):\n",
        "        similarities = []\n",
        "\n",
        "        for base_word, base_embedding in zip(base_words, base_embeddings):\n",
        "\n",
        "            cos_sim = cosine_similarity(token_embedding\n",
        "                                        .detach()\n",
        "                                        .numpy()\n",
        "                                        .reshape(1, -1),\n",
        "\n",
        "                                        base_embedding\n",
        "                                        .detach()\n",
        "                                        .numpy()\n",
        "                                        .reshape(1, -1)\n",
        "                                        )\n",
        "\n",
        "            similarities.append(cos_sim[0][0])\n",
        "\n",
        "        cos_sim_subject = cosine_similarity(token_embedding\n",
        "                                            .detach()\n",
        "                                            .numpy()\n",
        "                                            .reshape(1, -1),\n",
        "\n",
        "                                            school_subject_embedding\n",
        "                                            .detach()\n",
        "                                            .numpy()\n",
        "                                            .reshape(1, -1)\n",
        "                                            )\n",
        "\n",
        "        similarities.append(cos_sim_subject[0][0])\n",
        "\n",
        "        # check if the token is sufficiently similar to any base word\n",
        "        max_similarity = max(similarities)\n",
        "        if max_similarity > 0.98:\n",
        "            relevant_subjects.append(token)\n",
        "\n",
        "    # Remove duplicates using set datatype property\n",
        "    return list(set(relevant_subjects))\n",
        "\n",
        "# Example usage\n",
        "user_input = \"I love studying math and physical education, but chemistry is my favorite.\"\n",
        "cleaned_subjects = clean_subject_input(user_input)\n",
        "cleaned_subjects.append(\"informatics\")\n",
        "cleaned_subjects.remove(\"physical\")\n",
        "cleaned_subjects.remove(\"chemistry\")\n",
        "print(cleaned_subjects)\n",
        "\n",
        "subjects_embedding = extract_embeddings(cleaned_subjects)\n",
        "print(subjects_embedding.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "4um4_hINVGe5"
      },
      "outputs": [],
      "source": [
        "def combine_score(profession_embedding, subject_embedding, original_score, weight=0.7):\n",
        "\n",
        "    # cosine similarity between the embeddings\n",
        "    cos_sim = cosine_similarity(profession_embedding\n",
        "                                .detach()\n",
        "                                .numpy()\n",
        "                                .reshape(1, -1)\n",
        "                                ,\n",
        "\n",
        "                                subject_embedding\n",
        "                                .detach()\n",
        "                                .numpy()\n",
        "                                .reshape(1, -1)\n",
        "                                )\n",
        "\n",
        "    # combine score with predefined weight\n",
        "    combined_score = (weight * cos_sim[0][0]) + ((1 - weight) * original_score)\n",
        "\n",
        "    return combined_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSoXM1TlBM7j",
        "outputId": "58443654-97c9-4617-84c1-4f91755d0bb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Web Developers: 0.949806171655655\n",
            "Computer Network Architects: 0.9480694949626922\n",
            "Computer Programmers: 0.9449951827526093\n",
            "Environmental Engineers: 0.9440422177314758\n",
            "Validation Engineers: 0.9434145450592041\n",
            "Database Architects: 0.9433716416358948\n",
            "Database Administrators: 0.9411588549613952\n",
            "Computer Systems Analysts: 0.9411425590515137\n",
            "Operations Research Analysts: 0.9405641376972198\n",
            "Transportation Planners: 0.9404208362102509\n",
            "Computer User Support Specialists: 0.9404193699359893\n",
            "Materials Scientists: 0.9398408591747285\n",
            "Nanosystems Engineers: 0.9390329360961913\n",
            "Industrial Engineers: 0.9386328995227813\n",
            "Archeologists: 0.9383579552173614\n",
            "Web Administrators: 0.9382719278335572\n",
            "Materials Engineers: 0.9380653619766236\n",
            "Biomedical Engineers: 0.9379156708717347\n",
            "Intelligence Analysts: 0.9376263260841369\n",
            "Magnetic Resonance Imaging Technologists: 0.9375298142433166\n"
          ]
        }
      ],
      "source": [
        "def combine_subjects_and_riasec(user_input, answer, top_k=20):\n",
        "\n",
        "    # process user input\n",
        "    cleaned_subjects = clean_text(user_input)\n",
        "\n",
        "    if not cleaned_subjects:\n",
        "        return []\n",
        "\n",
        "    # generate embeddings for the cleaned subjects\n",
        "    subject_embeddings = extract_embeddings(cleaned_subjects)\n",
        "\n",
        "    # extract professions and their embeddings\n",
        "    profession_names = [item[0] for item in answer]\n",
        "\n",
        "    #print(profession_names[0:5])\n",
        "\n",
        "    original_scores = [item[1] for item in answer]\n",
        "    profession_embeddings = extract_embeddings(profession_names)\n",
        "\n",
        "    # calculate the combined scores for each profession\n",
        "\n",
        "    combined_scores = []\n",
        "\n",
        "    for i, profession_embedding in enumerate(profession_embeddings):\n",
        "\n",
        "        score = 0\n",
        "        for subject_embedding in subject_embeddings:\n",
        "            #print(profession_names[i], subject_embedding.shape, original_scores[i])\n",
        "            score += combine_score(profession_embedding, subject_embedding, original_scores[i])\n",
        "\n",
        "        # Average the scores if there are multiple subjects\n",
        "        score /= len(subject_embeddings)\n",
        "        combined_scores.append((profession_names[i], score))\n",
        "\n",
        "    #print(combined_scores[0:5])\n",
        "\n",
        "    # sort the results based on the combined score\n",
        "    sorted_results = sorted(combined_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # return the top_k results\n",
        "    return sorted_results[:top_k]\n",
        "\n",
        "user_input = \"I like math and humanities, but math I like more\"\n",
        "top_20_professions = combine_subjects_and_riasec(user_input, answer)\n",
        "\n",
        "\n",
        "for profession, score in top_20_professions:\n",
        "    print(f\"{profession}: {score}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
